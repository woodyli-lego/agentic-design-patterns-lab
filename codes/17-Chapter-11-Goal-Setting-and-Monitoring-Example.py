# MIT License
# Copyright (c) 2025 Mahtab Syed
# https://www.linkedin.com/in/mahtabsyed/

"""
Hands-On Code Example - Iteration 2
- To illustrate the Goal Setting and Monitoring pattern, we have an example using LangChain and OpenAI APIs:

Objective: Build an AI Agent which can write code for a specified use case based on specified goals:
- Accepts a coding problem (use case) in code or can be as input.
- Accepts a list of goals (e.g., "simple", "tested", "handles edge cases")  in code or can be input.
- Uses an LLM (like GPT-4o) to generate and refine Python code until the goals are met. (I am using max 5 iterations, this could be based on a set goal as well)
- To check if we have met our goals I am asking the LLM to judge this and answer just True or False which makes it easier to stop the iterations.
- Saves the final code in a .py file with a clean filename and a header comment.
"""

import os
import random
import re
from pathlib import Path
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv, find_dotenv

# ğŸ” Load environment variables
# ğŸ” åŠ è½½ç¯å¢ƒå˜é‡
_ = load_dotenv(find_dotenv())
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
   raise EnvironmentError("âŒ Please set the OPENAI_API_KEY environment variable.")
   # âŒ è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡

# âœ… Initialize OpenAI model
# âœ… åˆå§‹åŒ– OpenAI æ¨¡å‹
print("ğŸ“¡ Initializing OpenAI LLM (gpt-4o)...")
llm = ChatOpenAI(
   model="gpt-4o", # If you dont have access to got-4o use other OpenAI LLMs
                  # å¦‚æœä½ æ²¡æœ‰ gpt-4o çš„è®¿é—®æƒé™ï¼Œå¯ä»¥ä½¿ç”¨å…¶ä»– OpenAI LLM
   temperature=0.3,
   openai_api_key=OPENAI_API_KEY,
)

# --- Utility Functions ---
# --- å®ç”¨å·¥å…·å‡½æ•° ---

def generate_prompt(
   use_case: str, goals: list[str], previous_code: str = "", feedback: str = ""
) -> str:
   print("ğŸ“ Constructing prompt for code generation...")
   # ğŸ“ æ­£åœ¨æ„å»ºä»£ç ç”Ÿæˆçš„æç¤ºè¯...
   base_prompt = f"""
You are an AI coding agent. Your job is to write Python code based on the following use case:

Use Case: {use_case}

Your goals are:
{chr(10).join(f"- {g.strip()}" for g in goals)}
"""
   if previous_code:
       print("ğŸ”„ Adding previous code to the prompt for refinement.")
       # ğŸ”„ å°†ä¹‹å‰çš„ä»£ç æ·»åŠ åˆ°æç¤ºè¯ä¸­è¿›è¡Œæ”¹è¿›
       base_prompt += f"\nPreviously generated code:\n{previous_code}"
   if feedback:
       print("ğŸ“‹ Including feedback for revision.")
       # ğŸ“‹ åŒ…å«åé¦ˆä¿¡æ¯ç”¨äºä¿®è®¢
       base_prompt += f"\nFeedback on previous version:\n{feedback}\n"

   base_prompt += "\nPlease return only the revised Python code. Do not include comments or explanations outside the code."
   # è¯·åªè¿”å›ä¿®è®¢åçš„ Python ä»£ç ã€‚ä¸è¦åŒ…å«ä»£ç ä¹‹å¤–çš„æ³¨é‡Šæˆ–è§£é‡Š
   return base_prompt

def get_code_feedback(code: str, goals: list[str]) -> str:
   print("ğŸ” Evaluating code against the goals...")
   # ğŸ” æ­£åœ¨æ ¹æ®ç›®æ ‡è¯„ä¼°ä»£ç ...
   feedback_prompt = f"""
You are a Python code reviewer. A code snippet is shown below. Based on the following goals:

{chr(10).join(f"- {g.strip()}" for g in goals)}

Please critique this code and identify if the goals are met. Mention if improvements are needed for clarity, simplicity, correctness, edge case handling, or test coverage.

Code:
{code}
"""
   return llm.invoke(feedback_prompt)

def goals_met(feedback_text: str, goals: list[str]) -> bool:
   """
   Uses the LLM to evaluate whether the goals have been met based on the feedback text.
   Returns True or False (parsed from LLM output).
   """
   # ä½¿ç”¨ LLM æ ¹æ®åé¦ˆæ–‡æœ¬è¯„ä¼°ç›®æ ‡æ˜¯å¦è¾¾æˆ
   # è¿”å› True æˆ– Falseï¼ˆä» LLM è¾“å‡ºè§£æï¼‰
   review_prompt = f"""
You are an AI reviewer.

Here are the goals:
{chr(10).join(f"- {g.strip()}" for g in goals)}

Here is the feedback on the code:
\"\"\"
{feedback_text}
\"\"\"

Based on the feedback above, have the goals been met?

Respond with only one word: True or False.
"""
   # ä½ æ˜¯ä¸€ä¸ª AI è¯„å®¡å‘˜
   #
   # ç›®æ ‡å¦‚ä¸‹ï¼š
   # {chr(10).join(f"- {g.strip()}" for g in goals)}
   #
   # ä»¥ä¸‹æ˜¯ä»£ç çš„åé¦ˆï¼š
   # """
   # {feedback_text}
   # """
   #
   # æ ¹æ®ä»¥ä¸Šåé¦ˆï¼Œç›®æ ‡æ˜¯å¦å·²ç»è¾¾æˆï¼Ÿ
   #
   # è¯·åªå›ç­”ä¸€ä¸ªè¯ï¼šTrue æˆ– False
   response = llm.invoke(review_prompt).content.strip().lower()
   return response == "true"

def clean_code_block(code: str) -> str:
   # æ¸…ç†ä»£ç å—ï¼Œç§»é™¤ markdown æ ¼å¼çš„ä»£ç å—æ ‡è®°
   lines = code.strip().splitlines()
   if lines and lines[0].strip().startswith("```"):
       lines = lines[1:]
   if lines and lines[-1].strip() == "```":
       lines = lines[:-1]
   return "\n".join(lines).strip()

def add_comment_header(code: str, use_case: str) -> str:
   # ä¸ºä»£ç æ·»åŠ æ³¨é‡Šå¤´éƒ¨
   comment = f"# This Python program implements the following use case:\n# {use_case.strip()}\n"
   # # æ­¤ Python ç¨‹åºå®ç°äº†ä»¥ä¸‹ç”¨ä¾‹ï¼š\n# {use_case.strip()}\n
   return comment + "\n" + code

def to_snake_case(text: str) -> str:
   # å°†æ–‡æœ¬è½¬æ¢ä¸ºè›‡å½¢å‘½åæ³• (snake_case)
   text = re.sub(r"[^a-zA-Z0-9 ]", "", text)
   return re.sub(r"\s+", "_", text.strip().lower())

def save_code_to_file(code: str, use_case: str) -> str:
   print("ğŸ’¾ Saving final code to file...")
   # ğŸ’¾ æ­£åœ¨ä¿å­˜æœ€ç»ˆä»£ç åˆ°æ–‡ä»¶...

   summary_prompt = (
       f"Summarize the following use case into a single lowercase word or phrase, "
       f"no more than 10 characters, suitable for a Python filename:\n\n{use_case}"
   )
   # å°†ä»¥ä¸‹ç”¨ä¾‹æ€»ç»“ä¸ºå•ä¸ªå°å†™å•è¯æˆ–çŸ­è¯­ï¼Œä¸è¶…è¿‡ 10 ä¸ªå­—ç¬¦ï¼Œé€‚åˆä½œä¸º Python æ–‡ä»¶å
   raw_summary = llm.invoke(summary_prompt).content.strip()
   short_name = re.sub(r"[^a-zA-Z0-9_]", "", raw_summary.replace(" ", "_").lower())[:10]

   random_suffix = str(random.randint(1000, 9999))
   filename = f"{short_name}_{random_suffix}.py"
   filepath = Path.cwd() / filename

   with open(filepath, "w") as f:
       f.write(code)

   print(f"âœ… Code saved to: {filepath}")
   return str(filepath)

# --- Main Agent Function ---
# --- ä¸»è¦æ™ºèƒ½ä½“å‡½æ•° ---

def run_code_agent(use_case: str, goals_input: str, max_iterations: int = 5) -> str:
   # è¿è¡Œä»£ç æ™ºèƒ½ä½“çš„ä¸»è¦å‡½æ•°
   goals = [g.strip() for g in goals_input.split(",")]

   print(f"\nğŸ¯ Use Case: {use_case}")
   print("ğŸ¯ Goals:")
   for g in goals:
       print(f"  - {g}")

   previous_code = ""
   feedback = ""

   for i in range(max_iterations):
       print(f"\n=== ğŸ” Iteration {i + 1} of {max_iterations} ===")
       # === ğŸ” ç¬¬ {i + 1} æ¬¡è¿­ä»£ï¼Œå…± {max_iterations} æ¬¡ ===
       prompt = generate_prompt(use_case, goals, previous_code, feedback if isinstance(feedback, str) else feedback.content)

       print("ğŸš§ Generating code...")
       # ğŸš§ æ­£åœ¨ç”Ÿæˆä»£ç ...
       code_response = llm.invoke(prompt)
       raw_code = code_response.content.strip()
       code = clean_code_block(raw_code)
       print("\nğŸ§¾ Generated Code:\n" + "-" * 50 + f"\n{code}\n" + "-" * 50)
       # ğŸ§¾ ç”Ÿæˆçš„ä»£ç ï¼š

       print("\nğŸ“¤ Submitting code for feedback review...")
       # ğŸ“¤ æ­£åœ¨æäº¤ä»£ç è¿›è¡Œåé¦ˆå®¡æŸ¥...
       feedback = get_code_feedback(code, goals)
       feedback_text = feedback.content.strip()
       print("\nğŸ“¥ Feedback Received:\n" + "-" * 50 + f"\n{feedback_text}\n" + "-" * 50)
       # ğŸ“¥ æ”¶åˆ°çš„åé¦ˆï¼š

       if goals_met(feedback_text, goals):
           print("âœ… LLM confirms goals are met. Stopping iteration.")
           # âœ… LLM ç¡®è®¤ç›®æ ‡å·²è¾¾æˆã€‚åœæ­¢è¿­ä»£ã€‚
           break

       print("ğŸ› ï¸ Goals not fully met. Preparing for next iteration...")
       # ğŸ› ï¸ ç›®æ ‡æœªå®Œå…¨è¾¾æˆã€‚å‡†å¤‡ä¸‹ä¸€æ¬¡è¿­ä»£...
       previous_code = code

   final_code = add_comment_header(code, use_case)
   return save_code_to_file(final_code, use_case)

# --- CLI Test Run ---
# --- å‘½ä»¤è¡Œæµ‹è¯•è¿è¡Œ ---

if __name__ == "__main__":
   print("\nğŸ§  Welcome to the AI Code Generation Agent")
   # ğŸ§  æ¬¢è¿ä½¿ç”¨ AI ä»£ç ç”Ÿæˆæ™ºèƒ½ä½“

   # Example 1
   # ç¤ºä¾‹ 1
   use_case_input = "Write code to find BinaryGap of a given positive integer"
   goals_input = "Code simple to understand, Functionally correct, Handles comprehensive edge cases, Takes positive integer input only, prints the results with few examples"
   run_code_agent(use_case_input, goals_input)

   # Example 2
   # ç¤ºä¾‹ 2
   # use_case_input = "Write code to count the number of files in current directory and all its nested sub directories, and print the total count"
   # goals_input = (
   #     "Code simple to understand, Functionally correct, Handles comprehensive edge cases, Ignore recommendations for performance, Ignore recommendations for test suite use like unittest or pytest"
   # )
   # run_code_agent(use_case_input, goals_input)

   # Example 3
   # ç¤ºä¾‹ 3
   # use_case_input = "Write code which takes a command line input of a word doc or docx file and opens it and counts the number of words, and characters in it and prints all"
   # goals_input = "Code simple to understand, Functionally correct, Handles edge cases"
   # run_code_agent(use_case_input, goals_input)
